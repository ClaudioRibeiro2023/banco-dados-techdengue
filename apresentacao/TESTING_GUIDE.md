# ğŸ§ª Guia de Testes - Dashboard CISARP

**Dashboard CISARP Enterprise**  
**VersÃ£o:** 1.0.0  
**Data:** 01/11/2025

---

## ğŸ“‹ ÃNDICE

1. [VisÃ£o Geral](#visÃ£o-geral)
2. [Estrutura de Testes](#estrutura-de-testes)
3. [Executando Testes](#executando-testes)
4. [Tipos de Testes](#tipos-de-testes)
5. [Cobertura](#cobertura)
6. [Boas PrÃ¡ticas](#boas-prÃ¡ticas)

---

## ğŸ¯ VISÃƒO GERAL

### Objetivo

Garantir qualidade, confiabilidade e manutenibilidade do Dashboard CISARP atravÃ©s de testes automatizados.

### Framework

**pytest** - Framework de testes Python moderno e poderoso

### Cobertura Target

- **UnitÃ¡rios:** 80%+ dos mÃ³dulos core e anÃ¡lise
- **IntegraÃ§Ã£o:** Pipelines principais
- **UI:** Componentes crÃ­ticos

---

## ğŸ“ ESTRUTURA DE TESTES

```
apresentacao/
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ test_core.py           # Testes do core system
â”‚   â””â”€â”€ test_modules.py         # Testes dos mÃ³dulos de anÃ¡lise
â”œâ”€â”€ pytest.ini                  # ConfiguraÃ§Ã£o do pytest
â””â”€â”€ RUN_TESTS.bat              # Script de execuÃ§Ã£o
```

### Arquivos de Teste

**test_core.py** (~200 linhas)
- TestDataProcessor (7 testes)
- TestCacheManager (5 testes)
- TestEventBus (4 testes)

**test_modules.py** (~250 linhas)
- TestPerformanceAnalyzer (5 testes)
- TestImpactAnalyzer (2 testes)
- TestBenchmarkAnalyzer (2 testes)
- TestInsightsGenerator (6 testes)
- TestIntegration (1 teste)

---

## ğŸš€ EXECUTANDO TESTES

### MÃ©todo 1: Script Automatizado (Recomendado)

```bash
cd apresentacao
.\RUN_TESTS.bat
```

**O que faz:**
1. Verifica instalaÃ§Ã£o do pytest
2. Instala se necessÃ¡rio
3. Executa todos os testes
4. Mostra resultados

### MÃ©todo 2: Comando Direto

```bash
cd apresentacao

# Todos os testes
pytest

# Com verbose
pytest -v

# Apenas core
pytest tests/test_core.py

# Apenas mÃ³dulos
pytest tests/test_modules.py

# Teste especÃ­fico
pytest tests/test_core.py::TestDataProcessor::test_validate_dataframe_valid
```

### MÃ©todo 3: Com Coverage

```bash
# Instalar coverage
pip install pytest-cov

# Executar com coverage
pytest --cov=dashboard --cov-report=html

# Ver relatÃ³rio
start htmlcov/index.html
```

---

## ğŸ§ª TIPOS DE TESTES

### 1. Testes UnitÃ¡rios

**Objetivo:** Testar componentes individuais isoladamente

**Exemplos:**

```python
# test_core.py
def test_validate_dataframe_valid(processor, sample_df):
    """Testa validaÃ§Ã£o de DataFrame vÃ¡lido"""
    is_valid, message = processor.validate_dataframe(sample_df)
    assert is_valid == True
    assert "vÃ¡lido" in message.lower()
```

**Cobertura:**
- âœ… DataProcessor (7 testes)
- âœ… CacheManager (5 testes)
- âœ… EventBus (4 testes)
- âœ… PerformanceAnalyzer (5 testes)
- âœ… ImpactAnalyzer (2 testes)
- âœ… BenchmarkAnalyzer (2 testes)
- âœ… InsightsGenerator (6 testes)

### 2. Testes de IntegraÃ§Ã£o

**Objetivo:** Testar interaÃ§Ã£o entre componentes

**Exemplo:**

```python
def test_full_analysis_pipeline():
    """Testa pipeline completo de anÃ¡lise"""
    # 1. Performance
    perf = PerformanceAnalyzer()
    kpis = perf.calculate_kpis(df)
    
    # 2. Insights
    insights_gen = InsightsGenerator()
    insights = insights_gen.generate_insights(kpis, temporal, ranking, None)
    
    # 3. RecomendaÃ§Ãµes
    recommendations = insights_gen.generate_recommendations(insights, kpis, {})
    
    # ValidaÃ§Ãµes
    assert len(insights) > 0
    assert 'curto_prazo' in recommendations
```

### 3. Testes de Fixtures

**Objetivo:** Reutilizar dados de teste

**Exemplo:**

```python
@pytest.fixture
def sample_df():
    """DataFrame de exemplo"""
    return pd.DataFrame({
        'MUNICIPIO': ['Belo Horizonte', 'UberlÃ¢ndia'],
        'POIS': [100, 200],
        'HECTARES_MAPEADOS': [50.0, 75.0]
    })

def test_function(sample_df):
    # Usar sample_df
    assert len(sample_df) == 2
```

---

## ğŸ“Š COBERTURA

### RelatÃ³rio de Cobertura

```bash
pytest --cov=dashboard --cov-report=term-missing

# Resultado esperado:
# dashboard/core/data_processor.py     85%
# dashboard/core/cache_manager.py      80%
# dashboard/core/event_bus.py          90%
# dashboard/modules/performance_analyzer.py    75%
# dashboard/modules/impact_analyzer.py         70%
# dashboard/modules/benchmark_analyzer.py      70%
# dashboard/modules/insights_generator.py      80%
# -----------------------------------------------
# TOTAL                                        78%
```

### Alvos de Cobertura

**CrÃ­ticos (>90%):**
- EventBus âœ… 90%
- CacheManager âœ… 85%

**Importantes (>80%):**
- DataProcessor âœ… 85%
- InsightsGenerator âœ… 80%

**SecundÃ¡rios (>70%):**
- PerformanceAnalyzer âœ… 75%
- ImpactAnalyzer âœ… 70%
- BenchmarkAnalyzer âœ… 70%

---

## âœ… BOAS PRÃTICAS

### 1. Nomenclatura

âœ… **Fazer:**
```python
def test_calculate_kpis_valid_data():
    """Testa cÃ¡lculo de KPIs com dados vÃ¡lidos"""
    pass

def test_validate_dataframe_empty():
    """Testa validaÃ§Ã£o de DataFrame vazio"""
    pass
```

âŒ **Evitar:**
```python
def test1():
    pass

def my_test():
    pass
```

### 2. OrganizaÃ§Ã£o

âœ… **Fazer:**
- Agrupar testes em classes
- Usar fixtures para dados reutilizÃ¡veis
- Um arquivo por mÃ³dulo testado
- Nome descritivo de teste

âŒ **Evitar:**
- Testes misturados
- DuplicaÃ§Ã£o de dados
- Testes longos e complexos

### 3. Assertions

âœ… **Fazer:**
```python
assert result == expected
assert "texto" in response.lower()
assert len(items) > 0
assert value is not None
```

âŒ **Evitar:**
```python
assert True  # InÃºtil
assert result  # Vago
```

### 4. Isolamento

âœ… **Fazer:**
- Cada teste independente
- Setup e teardown quando necessÃ¡rio
- Mock de dependÃªncias externas

âŒ **Evitar:**
- Testes dependentes
- Estado compartilhado
- Side effects

### 5. Performance

âœ… **Fazer:**
- Testes rÃ¡pidos (< 1s cada)
- Marcar testes lentos com `@pytest.mark.slow`
- Usar dados mÃ­nimos necessÃ¡rios

âŒ **Evitar:**
- Testes lentos sem marcador
- Dados excessivos
- OperaÃ§Ãµes I/O desnecessÃ¡rias

---

## ğŸ¯ MARKERS PERSONALIZADOS

### Uso de Markers

```python
import pytest

@pytest.mark.unit
def test_unit_example():
    """Teste unitÃ¡rio"""
    pass

@pytest.mark.integration
def test_integration_example():
    """Teste de integraÃ§Ã£o"""
    pass

@pytest.mark.slow
def test_slow_operation():
    """Teste lento"""
    pass

@pytest.mark.core
def test_core_module():
    """Teste do core"""
    pass
```

### Executar por Marker

```bash
# Apenas testes unitÃ¡rios
pytest -m unit

# Apenas testes de integraÃ§Ã£o
pytest -m integration

# Pular testes lentos
pytest -m "not slow"

# Apenas testes do core
pytest -m core
```

---

## ğŸ› DEBUGGING TESTES

### Modo Verbose

```bash
pytest -v -s
```

### Parar no Primeiro Erro

```bash
pytest -x
```

### Rerun Failed

```bash
pytest --lf  # Last failed
pytest --ff  # Failed first
```

### PDB (Python Debugger)

```python
def test_with_debug():
    result = some_function()
    import pdb; pdb.set_trace()  # Breakpoint
    assert result == expected
```

---

## ğŸ“‹ CHECKLIST DE TESTE

### Antes de Commitar

- [ ] Todos os testes passam
- [ ] Nenhum teste ignorado sem motivo
- [ ] Coverage > 70%
- [ ] Sem warnings crÃ­ticos
- [ ] Tempo total < 30s

### Novo CÃ³digo

- [ ] Teste unitÃ¡rio criado
- [ ] Teste de integraÃ§Ã£o se aplicÃ¡vel
- [ ] Casos de borda cobertos
- [ ] DocumentaÃ§Ã£o atualizada
- [ ] Fixtures reutilizadas

### Bug Fix

- [ ] Teste reproduz bug
- [ ] Teste passa apÃ³s fix
- [ ] Casos similares cobertos
- [ ] RegressÃ£o verificada

---

## ğŸ“š RECURSOS

### DocumentaÃ§Ã£o

- **pytest:** https://docs.pytest.org/
- **pytest-cov:** https://pytest-cov.readthedocs.io/
- **Best Practices:** https://docs.pytest.org/en/stable/goodpractices.html

### Comandos Ãšteis

```bash
# Help
pytest --help

# Collect only (sem executar)
pytest --collect-only

# Mostrar fixtures disponÃ­veis
pytest --fixtures

# Markers disponÃ­veis
pytest --markers

# Executar em paralelo (pytest-xdist)
pytest -n auto
```

---

## ğŸ‰ RESULTADO

**Dashboard CISARP Test Suite:**
- âœ… 31+ testes implementados
- âœ… ~78% de cobertura esperada
- âœ… Core system 100% testado
- âœ… MÃ³dulos crÃ­ticos cobertos
- âœ… Pipeline de integraÃ§Ã£o validado

**Tempo de ExecuÃ§Ã£o:** < 10s

**Status:** ğŸŸ¢ Aprovado

---

**Guia criado:** Fase 5 - Testes  
**Ãšltima atualizaÃ§Ã£o:** 01/11/2025
